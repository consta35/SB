{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide": true
   },
   "source": [
    "Feature Selection and Regression Analysis\n",
    "$$\n",
    "\\renewcommand{\\like}{{\\cal L}}\n",
    "\\renewcommand{\\loglike}{{\\ell}}\n",
    "\\renewcommand{\\err}{{\\cal E}}\n",
    "\\renewcommand{\\dat}{{\\cal D}}\n",
    "\\renewcommand{\\hyp}{{\\cal H}}\n",
    "\\renewcommand{\\Ex}[2]{E_{#1}[#2]}\n",
    "\\renewcommand{\\x}{{\\mathbf x}}\n",
    "\\renewcommand{\\v}[1]{{\\mathbf #1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of Gene Expression and Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>ARPP21</th>\n",
       "      <th>ATP6AP1L</th>\n",
       "      <th>B3GALT2</th>\n",
       "      <th>C9orf116</th>\n",
       "      <th>CALB1</th>\n",
       "      <th>CCDC80</th>\n",
       "      <th>CREB3L1</th>\n",
       "      <th>CTXN3</th>\n",
       "      <th>DACH1</th>\n",
       "      <th>GABRA3</th>\n",
       "      <th>GARNL3</th>\n",
       "      <th>GLRA3</th>\n",
       "      <th>GPR52</th>\n",
       "      <th>KRT80</th>\n",
       "      <th>NRIP3</th>\n",
       "      <th>PAPPA2</th>\n",
       "      <th>Pdyn</th>\n",
       "      <th>PLA2G2C</th>\n",
       "      <th>SOWAHA</th>\n",
       "      <th>SPON1</th>\n",
       "      <th>SYNJ2</th>\n",
       "      <th>VSTM2L</th>\n",
       "      <th>OF_HPA1_T_AUC</th>\n",
       "      <th>OF_HPA1_Net_AUC</th>\n",
       "      <th>OF_HPA2_T_AUC</th>\n",
       "      <th>OF_HPA2_Net_AUC</th>\n",
       "      <th>OFA1_Total</th>\n",
       "      <th>OFA2_Total</th>\n",
       "      <th>Startle</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beta1_F1</td>\n",
       "      <td>3430</td>\n",
       "      <td>1607</td>\n",
       "      <td>2086</td>\n",
       "      <td>30</td>\n",
       "      <td>497</td>\n",
       "      <td>260</td>\n",
       "      <td>482</td>\n",
       "      <td>2023</td>\n",
       "      <td>133</td>\n",
       "      <td>6661</td>\n",
       "      <td>1683</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>88</td>\n",
       "      <td>16732</td>\n",
       "      <td>81</td>\n",
       "      <td>254</td>\n",
       "      <td>171</td>\n",
       "      <td>582</td>\n",
       "      <td>5017</td>\n",
       "      <td>2651</td>\n",
       "      <td>1275</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>492.43</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beta2_F1</td>\n",
       "      <td>3193</td>\n",
       "      <td>1683</td>\n",
       "      <td>1751</td>\n",
       "      <td>32</td>\n",
       "      <td>489</td>\n",
       "      <td>136</td>\n",
       "      <td>386</td>\n",
       "      <td>1789</td>\n",
       "      <td>73</td>\n",
       "      <td>6050</td>\n",
       "      <td>1792</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>13215</td>\n",
       "      <td>66</td>\n",
       "      <td>362</td>\n",
       "      <td>134</td>\n",
       "      <td>650</td>\n",
       "      <td>5320</td>\n",
       "      <td>3080</td>\n",
       "      <td>800</td>\n",
       "      <td>2901.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>712.38</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beta3_F1</td>\n",
       "      <td>4427</td>\n",
       "      <td>2056</td>\n",
       "      <td>1261</td>\n",
       "      <td>14</td>\n",
       "      <td>364</td>\n",
       "      <td>125</td>\n",
       "      <td>346</td>\n",
       "      <td>1289</td>\n",
       "      <td>119</td>\n",
       "      <td>4921</td>\n",
       "      <td>1366</td>\n",
       "      <td>23</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>13871</td>\n",
       "      <td>88</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>462</td>\n",
       "      <td>3018</td>\n",
       "      <td>2570</td>\n",
       "      <td>1412</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>588.8</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>360.00</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beta4_F1</td>\n",
       "      <td>3836</td>\n",
       "      <td>2555</td>\n",
       "      <td>1753</td>\n",
       "      <td>30</td>\n",
       "      <td>520</td>\n",
       "      <td>247</td>\n",
       "      <td>482</td>\n",
       "      <td>2737</td>\n",
       "      <td>129</td>\n",
       "      <td>5432</td>\n",
       "      <td>1813</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>173</td>\n",
       "      <td>22119</td>\n",
       "      <td>160</td>\n",
       "      <td>437</td>\n",
       "      <td>167</td>\n",
       "      <td>798</td>\n",
       "      <td>3635</td>\n",
       "      <td>3420</td>\n",
       "      <td>803</td>\n",
       "      <td>2327.0</td>\n",
       "      <td>570.6</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>148.38</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control1_F1</td>\n",
       "      <td>9818</td>\n",
       "      <td>1733</td>\n",
       "      <td>935</td>\n",
       "      <td>95</td>\n",
       "      <td>2647</td>\n",
       "      <td>120</td>\n",
       "      <td>381</td>\n",
       "      <td>1277</td>\n",
       "      <td>393</td>\n",
       "      <td>4692</td>\n",
       "      <td>1140</td>\n",
       "      <td>103</td>\n",
       "      <td>241</td>\n",
       "      <td>953</td>\n",
       "      <td>10578</td>\n",
       "      <td>61</td>\n",
       "      <td>1733</td>\n",
       "      <td>308</td>\n",
       "      <td>2926</td>\n",
       "      <td>3440</td>\n",
       "      <td>2713</td>\n",
       "      <td>2490</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>444.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>141.50</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sample  ARPP21  ATP6AP1L  B3GALT2  C9orf116  CALB1  CCDC80  CREB3L1  CTXN3  DACH1  GABRA3  GARNL3  GLRA3  GPR52  KRT80  NRIP3  PAPPA2  Pdyn  PLA2G2C  SOWAHA  SPON1  SYNJ2  VSTM2L  OF_HPA1_T_AUC  OF_HPA1_Net_AUC  OF_HPA2_T_AUC  OF_HPA2_Net_AUC  OFA1_Total  OFA2_Total  Startle     Group\n",
       "0     Beta1_F1    3430      1607     2086        30    497     260      482   2023    133    6661    1683     14     34     88  16732      81   254      171     582   5017   2651    1275         1695.0           1338.0         2269.0           1993.0      2631.0       263.0   492.43      Beta\n",
       "1     Beta2_F1    3193      1683     1751        32    489     136      386   1789     73    6050    1792     14     36     80  13215      66   362      134     650   5320   3080     800         2901.0           1768.0         2336.0           1536.0      1417.0        43.0   712.38      Beta\n",
       "2     Beta3_F1    4427      2056     1261        14    364     125      346   1289    119    4921    1366     23     68     72  13871      88   168      122     462   3018   2570    1412         1436.0            588.8         2045.0           1868.0       344.0       956.0   360.00      Beta\n",
       "3     Beta4_F1    3836      2555     1753        30    520     247      482   2737    129    5432    1813     17     56    173  22119     160   437      167     798   3635   3420     803         2327.0            570.6         2821.0           1808.0       551.0      2203.0   148.38      Beta\n",
       "4  Control1_F1    9818      1733      935        95   2647     120      381   1277    393    4692    1140    103    241    953  10578      61  1733      308    2926   3440   2713    2490         1729.0           1334.0         2701.0            -12.3       444.0       780.0   141.50  Control "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflog = pd.read_csv(\"data/PFC_22genes_AllBehav.csv\")\n",
    "dflog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARPP21</th>\n",
       "      <th>ATP6AP1L</th>\n",
       "      <th>B3GALT2</th>\n",
       "      <th>C9orf116</th>\n",
       "      <th>CALB1</th>\n",
       "      <th>CCDC80</th>\n",
       "      <th>CREB3L1</th>\n",
       "      <th>CTXN3</th>\n",
       "      <th>DACH1</th>\n",
       "      <th>GABRA3</th>\n",
       "      <th>GARNL3</th>\n",
       "      <th>GLRA3</th>\n",
       "      <th>GPR52</th>\n",
       "      <th>KRT80</th>\n",
       "      <th>NRIP3</th>\n",
       "      <th>PAPPA2</th>\n",
       "      <th>Pdyn</th>\n",
       "      <th>PLA2G2C</th>\n",
       "      <th>SOWAHA</th>\n",
       "      <th>SPON1</th>\n",
       "      <th>SYNJ2</th>\n",
       "      <th>VSTM2L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3430</td>\n",
       "      <td>1607</td>\n",
       "      <td>2086</td>\n",
       "      <td>30</td>\n",
       "      <td>497</td>\n",
       "      <td>260</td>\n",
       "      <td>482</td>\n",
       "      <td>2023</td>\n",
       "      <td>133</td>\n",
       "      <td>6661</td>\n",
       "      <td>1683</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>88</td>\n",
       "      <td>16732</td>\n",
       "      <td>81</td>\n",
       "      <td>254</td>\n",
       "      <td>171</td>\n",
       "      <td>582</td>\n",
       "      <td>5017</td>\n",
       "      <td>2651</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3193</td>\n",
       "      <td>1683</td>\n",
       "      <td>1751</td>\n",
       "      <td>32</td>\n",
       "      <td>489</td>\n",
       "      <td>136</td>\n",
       "      <td>386</td>\n",
       "      <td>1789</td>\n",
       "      <td>73</td>\n",
       "      <td>6050</td>\n",
       "      <td>1792</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>13215</td>\n",
       "      <td>66</td>\n",
       "      <td>362</td>\n",
       "      <td>134</td>\n",
       "      <td>650</td>\n",
       "      <td>5320</td>\n",
       "      <td>3080</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4427</td>\n",
       "      <td>2056</td>\n",
       "      <td>1261</td>\n",
       "      <td>14</td>\n",
       "      <td>364</td>\n",
       "      <td>125</td>\n",
       "      <td>346</td>\n",
       "      <td>1289</td>\n",
       "      <td>119</td>\n",
       "      <td>4921</td>\n",
       "      <td>1366</td>\n",
       "      <td>23</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>13871</td>\n",
       "      <td>88</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>462</td>\n",
       "      <td>3018</td>\n",
       "      <td>2570</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3836</td>\n",
       "      <td>2555</td>\n",
       "      <td>1753</td>\n",
       "      <td>30</td>\n",
       "      <td>520</td>\n",
       "      <td>247</td>\n",
       "      <td>482</td>\n",
       "      <td>2737</td>\n",
       "      <td>129</td>\n",
       "      <td>5432</td>\n",
       "      <td>1813</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>173</td>\n",
       "      <td>22119</td>\n",
       "      <td>160</td>\n",
       "      <td>437</td>\n",
       "      <td>167</td>\n",
       "      <td>798</td>\n",
       "      <td>3635</td>\n",
       "      <td>3420</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9818</td>\n",
       "      <td>1733</td>\n",
       "      <td>935</td>\n",
       "      <td>95</td>\n",
       "      <td>2647</td>\n",
       "      <td>120</td>\n",
       "      <td>381</td>\n",
       "      <td>1277</td>\n",
       "      <td>393</td>\n",
       "      <td>4692</td>\n",
       "      <td>1140</td>\n",
       "      <td>103</td>\n",
       "      <td>241</td>\n",
       "      <td>953</td>\n",
       "      <td>10578</td>\n",
       "      <td>61</td>\n",
       "      <td>1733</td>\n",
       "      <td>308</td>\n",
       "      <td>2926</td>\n",
       "      <td>3440</td>\n",
       "      <td>2713</td>\n",
       "      <td>2490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARPP21  ATP6AP1L  B3GALT2  C9orf116  CALB1  CCDC80  CREB3L1  CTXN3  DACH1  GABRA3  GARNL3  GLRA3  GPR52  KRT80  NRIP3  PAPPA2  Pdyn  PLA2G2C  SOWAHA  SPON1  SYNJ2  VSTM2L\n",
       "0    3430      1607     2086        30    497     260      482   2023    133    6661    1683     14     34     88  16732      81   254      171     582   5017   2651    1275\n",
       "1    3193      1683     1751        32    489     136      386   1789     73    6050    1792     14     36     80  13215      66   362      134     650   5320   3080     800\n",
       "2    4427      2056     1261        14    364     125      346   1289    119    4921    1366     23     68     72  13871      88   168      122     462   3018   2570    1412\n",
       "3    3836      2555     1753        30    520     247      482   2737    129    5432    1813     17     56    173  22119     160   437      167     798   3635   3420     803\n",
       "4    9818      1733      935        95   2647     120      381   1277    393    4692    1140    103    241    953  10578      61  1733      308    2926   3440   2713    2490"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Separate Gene Expression\n",
    "data = dflog.loc[:,'ARPP21':'VSTM2L']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2631.0\n",
       "1    1417.0\n",
       "2     344.0\n",
       "3     551.0\n",
       "4     444.0\n",
       "Name: OFA1_Total, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate Behavioural Outcome Target\n",
    "target= dflog.loc[:,'OFA1_Total']\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1.0, 'C9orf116'), (2.0, 'GLRA3'), (3.0, 'GPR52'), (4.0, 'CALB1'), (5.0, 'CCDC80'), (6.0, 'PAPPA2'), (7.0, 'DACH1'), (8.0, 'CTXN3'), (9.0, 'VSTM2L'), (10.0, 'SOWAHA'), (11.0, 'KRT80'), (12.0, 'B3GALT2'), (13.0, 'ATP6AP1L'), (14.0, 'GARNL3'), (15.0, 'SPON1'), (16.0, 'PLA2G2C'), (17.0, 'CREB3L1'), (18.0, 'SYNJ2'), (19.0, 'NRIP3'), (20.0, 'GABRA3'), (21.0, 'ARPP21'), (22.0, 'Pdyn')]\n"
     ]
    }
   ],
   "source": [
    "## RFE Features selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "X = data\n",
    "Y = target\n",
    "names = data.keys()\n",
    " \n",
    "#use linear regression as the model\n",
    "lr = LinearRegression()\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(X,Y)\n",
    " \n",
    "print \"Features sorted by their rank:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from minepy import MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranks = {}\n",
    " \n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    " \n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X, Y)\n",
    "ranks[\"Linear reg\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    " \n",
    "ridge = Ridge(alpha=7)\n",
    "ridge.fit(X, Y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    " \n",
    " \n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(X, Y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    " \n",
    " \n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X, Y)\n",
    "ranks[\"Stability\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    " \n",
    "#stop the search when 5 features are left (they will get equal scores)\n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe.fit(X,Y)\n",
    "ranks[\"RFE\"] = rank_to_dict(map(float, rfe.ranking_), names, order=-1)\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,Y)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    " \n",
    " \n",
    "f, pval  = f_regression(X, Y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Mean = []\n",
    "for i in (1,len(result)):\n",
    "    m = np.mean(result[:i])\n",
    "    Mean.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer= result.append(Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = answer.sort_values(by ='Mean', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr.</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Linear reg</th>\n",
       "      <th>Mean</th>\n",
       "      <th>RF</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GLRA3</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9orf116</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR52</th>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCDC80</th>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPPA2</th>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLA2G2C</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GABRA3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARPP21</th>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.253182</td>\n",
       "      <td>0.149545</td>\n",
       "      <td>0.126818</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.114091</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.122273</td>\n",
       "      <td>0.637727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DACH1</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTM2L</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3GALT2</th>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATP6AP1L</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRT80</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOWAHA</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPON1</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALB1</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREB3L1</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NRIP3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYNJ2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARNL3</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTXN3</th>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pdyn</th>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Corr.     Lasso  Linear reg   Mean        RF       RFE     Ridge  Stability\n",
       "GLRA3     0.140000  1.000000    1.000000  0.730  0.030000  1.000000  1.000000   0.940000\n",
       "C9orf116  0.350000  0.830000    0.140000  0.470  0.010000  1.000000  0.180000   0.770000\n",
       "GPR52     0.460000  0.460000    0.160000  0.430  0.200000  1.000000  0.120000   0.610000\n",
       "CCDC80    0.070000  0.230000    0.390000  0.410  0.110000  1.000000  0.350000   0.730000\n",
       "PAPPA2    0.490000  0.080000    0.080000  0.400  0.240000  0.940000  0.070000   0.890000\n",
       "PLA2G2C   0.510000  0.050000    0.260000  0.340  0.100000  0.350000  0.240000   0.900000\n",
       "GABRA3    1.000000  0.000000    0.010000  0.330  0.290000  0.120000  0.000000   0.920000\n",
       "0         0.570000  0.000000    0.000000  0.300  1.000000  0.060000  0.000000   0.440000\n",
       "ARPP21    0.570000  0.000000    0.000000  0.300  1.000000  0.060000  0.000000   0.440000\n",
       "1         0.253182  0.149545    0.126818  0.285  0.114091  0.590909  0.122273   0.637727\n",
       "DACH1     0.180000  0.240000    0.020000  0.280  0.030000  0.880000  0.010000   0.620000\n",
       "VSTM2L    0.100000  0.040000    0.010000  0.260  0.060000  0.760000  0.010000   0.840000\n",
       "B3GALT2   0.260000  0.020000    0.070000  0.240  0.040000  0.590000  0.070000   0.600000\n",
       "ATP6AP1L  0.240000  0.010000    0.040000  0.240  0.030000  0.530000  0.040000   0.780000\n",
       "KRT80     0.280000  0.030000    0.070000  0.220  0.030000  0.650000  0.060000   0.450000\n",
       "SOWAHA    0.290000  0.040000    0.030000  0.210  0.000000  0.710000  0.040000   0.350000\n",
       "SPON1     0.210000  0.000000    0.030000  0.210  0.150000  0.410000  0.030000   0.630000\n",
       "CALB1     0.240000  0.010000    0.090000  0.210  0.020000  1.000000  0.080000   0.020000\n",
       "CREB3L1   0.050000  0.150000    0.170000  0.200  0.030000  0.290000  0.170000   0.550000\n",
       "NRIP3     0.000000  0.000000    0.000000  0.180  0.050000  0.180000  0.000000   1.000000\n",
       "SYNJ2     0.000000  0.020000    0.050000  0.180  0.000000  0.240000  0.050000   0.880000\n",
       "GARNL3    0.040000  0.050000    0.110000  0.160  0.010000  0.470000  0.110000   0.350000\n",
       "CTXN3     0.030000  0.020000    0.060000  0.140  0.020000  0.820000  0.060000   0.000000\n",
       "Pdyn      0.060000  0.010000    0.000000  0.130  0.060000  0.000000  0.000000   0.760000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer\n",
    "#### It appears as though GLRA3, C9orf116, and GPR52 are most highly influential on OFA1_total. \n",
    "#### How do I now incoroprate this into a model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set I</h3>\n",
    "\n",
    "<ul>\n",
    "  <li> <b>Exercise:</b> Create a scatter plot of Weight vs. Height\n",
    "  <li> <b>Exercise:</b> Color the points differently by Gender\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Datasets\n",
    "\n",
    "When fitting models, we would like to ensure two things:\n",
    "\n",
    "* We have found the best model (in terms of model parameters).\n",
    "* The model is highly likely to generalize i.e. perform well on unseen data.\n",
    "\n",
    "<br/>\n",
    "<div class=\"span5 alert alert-success\">\n",
    "<h4>Purpose of splitting data into Training/testing sets</h4>\n",
    "<ul>\n",
    "  <li> We built our model with the requirement that the model fit the data well. </li>\n",
    "  <li> As a side-effect, the model will fit <b>THIS</b> dataset well. What about new data? </li>\n",
    "    <ul>\n",
    "      <li> We wanted the model for predictions, right?</li>\n",
    "    </ul>\n",
    "  <li> One simple solution, leave out some data (for <b>testing</b>) and <b>train</b> the model on the rest </li>\n",
    "  <li> This also leads directly to the idea of cross-validation, next section. </li>  \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try a basic Logistic Regression:\n",
    "\n",
    "* Split the data into a training and test (hold-out) set\n",
    "* Train on the training set, and test for accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      12.000000\n",
       "mean     1270.458333\n",
       "std       787.557428\n",
       "min        14.000000\n",
       "25%       676.250000\n",
       "50%      1401.000000\n",
       "75%      1744.750000\n",
       "max      2631.000000\n",
       "Name: OFA1_Total, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta=dflog[dflog.Group ==\"Beta\"]\n",
    "\n",
    "beta.OFA1_Total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dflog[['GLRA3','C9orf116','GPR52']].values,\n",
    "                                              (dflog.Group == \"Beta\").values,random_state=5)\n",
    "Xlr\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dflog[['GABRA3','DACH1','OFA1_Total']].values,\n",
    "                                              (dflog.Group == \"Beta\").values,random_state=5)\n",
    "Xlr\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has some hyperparameters we can tune for hopefully better performance. For tuning the parameters of your model, you will use a mix of *cross-validation* and *grid search*. In Logistic Regression, the most important parameter to tune is the *regularization parameter* `C`. Note that the regularization parameter is not always part of the logistic regression model. \n",
    "\n",
    "The regularization parameter is used to control for unlikely high regression coefficients, and in other cases can be used when data is sparse, as a method of feature selection.\n",
    "\n",
    "You will now implement some code to perform model tuning and selecting the regularization parameter $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following `cv_score` function to perform K-fold cross-validation and apply a scoring function to each test fold. In this incarnation we use accuracy score as the default scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 6\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of using the `cv_score` function for a basic logistic regression model without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, Xlr, ylr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set II</h3>\n",
    "\n",
    "<b>Exercise:</b> Implement the following search procedure to find a good model\n",
    "<ul>\n",
    "<li> You are given a list of possible values of `C` below\n",
    "<li> For each C:\n",
    "  <ol>\n",
    "  <li> Create a logistic regression model with that value of C\n",
    "  <li> Find the average score for this model using the `cv_score` function **only on the training set** `(Xlr, ylr)`\n",
    "  </ol>\n",
    "<li> Pick the C with the highest average score\n",
    "</ul>\n",
    "Your goal is to find the best model parameters based *only* on the training set, without showing the model test set at all (which is why the test set is also called a *hold-out* set).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667 1\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "# your turn\n",
    "max_score = 0\n",
    "\n",
    "for C in Cs:\n",
    "        clf = LogisticRegression(C=C)\n",
    "        score = cv_score(clf, Xlr, ylr)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_C =C\n",
    "print max_score, best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set III</h3>\n",
    "**Exercise:** Now you want to estimate how this model will predict on unseen data in the following way:\n",
    "<ol>\n",
    "<li> Use the C you obtained from the procedure earlier and train a Logistic Regression on the training data\n",
    "<li> Calculate the accuracy on the test data\n",
    "</ol>\n",
    "\n",
    "<p>You may notice that this particular value of `C` may or may not do as well as simply running the default model on a random train-test split. </p>\n",
    "\n",
    "<ul>\n",
    "<li> Do you think that's a problem? \n",
    "<li> Why do we need to do this whole cross-validation and grid search stuff anyway?\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "# your turn\n",
    "clfl = LogisticRegression(C=0.1)\n",
    "clfl.fit(Xlr, ylr)\n",
    "# Print the accuracy from the test data.\n",
    "print(accuracy_score(clfl.predict(Xtestlr), ytestlr))\n",
    "\n",
    "## Cross validation is used to minimize the risk of overfitting a model. By optimizing the C value, we find the best model,\n",
    "## and cross validation allows us to ensure that the model will also generalize to novel data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Box Grid Search in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn, as with many other Python packages, provides utilities to perform common operations so you do not have to do it manually. It is important to understand the mechanics of each operation, but at a certain point, you will want to use the utility instead to save time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set IV</h3>\n",
    "\n",
    "<b>Exercise:</b> Use scikit-learn's [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) tool to perform cross validation and grid search. \n",
    "\n",
    "* Instead of writing your own loops above to iterate over the model parameters, can you use GridSearchCV to find the best model over the training set? \n",
    "* Does it give you the same best value of `C`?\n",
    "* How does this model you've obtained perform on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " {'C': 100},\n",
       " 0.61111111111111116,\n",
       " [mean: 0.55556, std: 0.35978, params: {'C': 0.0001},\n",
       "  mean: 0.55556, std: 0.21473, params: {'C': 0.001},\n",
       "  mean: 0.55556, std: 0.21473, params: {'C': 0.1},\n",
       "  mean: 0.55556, std: 0.21473, params: {'C': 1},\n",
       "  mean: 0.55556, std: 0.21473, params: {'C': 10},\n",
       "  mean: 0.61111, std: 0.27588, params: {'C': 100}])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your turn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clfl2=LogisticRegression()\n",
    "parameters = {\"C\": [0.0001, 0.001, 0.1, 1, 10, 100]}\n",
    "fitmodel = GridSearchCV(clfl2, param_grid=parameters, cv=5, scoring=\"accuracy\")\n",
    "fitmodel.fit(Xlr, ylr)\n",
    "fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_\n",
    "\n",
    "## This method gives a different value of C, but it's irrelevant because there are more than 1 value of C that fit the model \n",
    "## best. both C=0.1, and C=0.001 are equivalent. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "cfl2=LogisticRegression(C=0.001)\n",
    "clfl2.fit(Xlr, ylr)\n",
    "print(accuracy_score(clfl2.predict(Xtestlr), ytestlr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Walkthrough of the Math Behind Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
